{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layoutparser as lp\n",
    "import pymupdf\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import faiss\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel, CLIPConfig, CLIPTokenizer, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import voyageai\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "device = 'gpu' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment section: Q-A over 3 documents\n",
    "from document_analysis import DocumentAnalysis\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Helper functions\n",
    "# Formatting Q-A pairs with COCO annotations\n",
    "# Formula for IoU\n",
    "def calculate_iou(box1, box2):\n",
    "    box1 = np.array(box1, dtype=np.float32)\n",
    "    box2 = np.array(box2, dtype=np.float32)\n",
    "\n",
    "    # Compute intersection coordinates\n",
    "    inter_x_min = np.maximum(box1[0], box2[0])\n",
    "    inter_y_min = np.maximum(box1[1], box2[1])\n",
    "    inter_x_max = np.minimum(box1[2], box2[2])\n",
    "    inter_y_max = np.minimum(box1[3], box2[3])\n",
    "\n",
    "    # Compute intersection area\n",
    "    inter_width = np.maximum(0, inter_x_max - inter_x_min)\n",
    "    inter_height = np.maximum(0, inter_y_max - inter_y_min)\n",
    "    inter_area = inter_width * inter_height\n",
    "\n",
    "    # Compute area of both boxes\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    # Compute union area with numerical stability\n",
    "    union_area = np.maximum(box1_area + box2_area - inter_area, 1e-10)\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = inter_area / union_area\n",
    "    return np.clip(iou, 0.0, 1.0)\n",
    "\n",
    "# Convert (x, y, width, height) to (x1, y1, x2, y2)\n",
    "def coco_to_coordinates(bbox):\n",
    "    x, y, width, height = bbox # unwrap\n",
    "    return [x, y, x + width, y + height]\n",
    "\n",
    "\n",
    "# Filename init\n",
    "data_dir = \"../data/\"\n",
    "data_annotations_dir = \"../data/annotations/\"\n",
    "doc_list = [\"1706.03762.pdf\", \"imagenet-classification.pdf\", \"2010.11929v2.pdf\"]\n",
    "annotations_list = [\"annotations-attention\", \"annotations-imagenet\", \"annotations-vit\"]\n",
    "qa_pairs_list = [\"qa-pairs-attention\", \"qa-pairs-imagenet\", \"qa-pairs-vit\"]\n",
    "\n",
    "# Metrics\n",
    "# Total pages, questions and total regions fixed at 20*3 = 60\n",
    "correct_pages_top1 = 0\n",
    "correct_regions_top1 = 0\n",
    "correct_regions_iou_top1 = 0.0\n",
    "correct_pages_top5 = 0\n",
    "correct_regions_top5 = 0\n",
    "correct_regions_iou_top5 = 0.0\n",
    "\n",
    "for doc_name, annotations_name, qa_pairs_name in zip(doc_list, annotations_list, qa_pairs_list):\n",
    "    # if doc_name == \"1706.03762.pdf\": continue\n",
    "    print(f\"\\n\\nCurrent doc: {doc_name}\")\n",
    "    annotations = json.load(open(data_annotations_dir + annotations_name + '.json', 'r'))\n",
    "    qa_pairs = json.load(open(data_annotations_dir + qa_pairs_name + '.json', 'r'))\n",
    "\n",
    "    # New pipeline, read and process \n",
    "    pipeline = DocumentAnalysis(vector_dir = '../data/.vectorstore/')\n",
    "    # doc = pipeline.read_from_path(data_dir + doc_name)\n",
    "    # pipeline.process_document(doc)\n",
    "    # pipeline.faiss_persist(subdir = doc_name + '/') # one-time, update schema\n",
    "    pipeline.faiss_read(subdir = doc_name + '/') # If document has been processed and stored prior\n",
    "\n",
    "    # Metrics for current paper\n",
    "    cpt1_trial = 0\n",
    "    crt1_trial = 0\n",
    "    crtiou1_trial = 0.0\n",
    "    cpt5_trial = 0\n",
    "    crt5_trial = 0\n",
    "    crtiou5_trial = 0.0\n",
    "\n",
    "    # Q-A assessment\n",
    "    verbose=True\n",
    "    for qa in qa_pairs:\n",
    "        qvalue, qpage, qbbox = qa['answer'].values()\n",
    "        qbbox = tuple(coco_to_coordinates(qbbox)) # Standardize to LayoutParser bbox system\n",
    "\n",
    "        answers = pipeline.search_faiss(qa['question'])\n",
    "        atext = [a['content'] for a in answers]\n",
    "        apages = [a['page']+1 for a in answers] # Add 1 to convert from index to numbering\n",
    "        abboxes = [a['bbox'] for a in answers]\n",
    "\n",
    "        # Verbose illustration\n",
    "        if verbose:\n",
    "            print(f'\\nQuestion: {qa['question']}')\n",
    "            # print(f'\\nground: {qpage}, {qbbox}, {qa['question']}')\n",
    "            for i in zip(atext, apages, abboxes):\n",
    "                print(i)\n",
    "\n",
    "        # Top-1 metric\n",
    "        # apages is ordered in decreasing order\n",
    "        if apages[0] == qpage:\n",
    "            cpt1_trial += 1\n",
    "            iou = calculate_iou(qbbox, abboxes[0])\n",
    "            if verbose: print(f'iou_top1: {iou}')\n",
    "            if iou > 0.5: \n",
    "                crt1_trial += 1\n",
    "                crtiou1_trial += iou\n",
    "        \n",
    "        # Top-5 metric\n",
    "        if qpage in apages:\n",
    "            if verbose: print(qpage, apages)\n",
    "            cpt5_trial += 1\n",
    "            for apage, abbox in zip(apages, abboxes):\n",
    "                if apage == qpage:\n",
    "                    iou = calculate_iou(qbbox, abbox)\n",
    "                    if verbose: print(f'iou_top5: {iou}')\n",
    "                    if iou > 0.5: \n",
    "                        crt5_trial += 1\n",
    "                        crtiou5_trial += iou\n",
    "                        break # If correct found, skip remaining chunks\n",
    "    # Print document-specific metrics\n",
    "    qa_length = len(qa_pairs)\n",
    "    print(\"Top-1\")\n",
    "    print(f'Correct pages: {cpt1_trial/qa_length}')\n",
    "    print(f'Correct regions: {crt1_trial/qa_length}, IoU: {crtiou1_trial/crt1_trial}')\n",
    "    print(\"Top-5\")\n",
    "    print(f\"Correct pages: {cpt5_trial/qa_length}\")\n",
    "    print(f'Correct regions: {crt5_trial/qa_length}, IoU: {crtiou5_trial/crt5_trial}')\n",
    "    print('\\n\\n')\n",
    "\n",
    "    # Aggregate\n",
    "    correct_pages_top1 += cpt1_trial\n",
    "    correct_regions_top1 += crt1_trial\n",
    "    correct_regions_iou_top1 += crtiou1_trial\n",
    "    correct_pages_top5 += cpt5_trial\n",
    "    correct_regions_top5 += crt5_trial\n",
    "    correct_regions_iou_top5 += crtiou5_trial\n",
    "\n",
    "# Print overall metrics\n",
    "print(\"Top-1\")\n",
    "print(f'Correct pages: {correct_pages_top1/60}')\n",
    "print(f'Correct regions: {correct_regions_top1/60}, IoU: {correct_regions_iou_top1/correct_regions_top1}')\n",
    "print(\"Top-5\")\n",
    "print(f\"Correct pages: {correct_pages_top5/60}\")\n",
    "print(f'Correct regions: {correct_regions_top5/60}, IoU: {correct_regions_iou_top5/correct_regions_top5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters (Detectron2): 44051248\n"
     ]
    }
   ],
   "source": [
    "# Counting model sizes\n",
    "# Import libraries in first cell\n",
    "\n",
    "# Cross encoder size\n",
    "crossencoder = AutoModelForSequenceClassification.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L6-v2\")\n",
    "print(f\"Total number of parameters (Cross Encoder): {crossencoder.num_parameters()}\")\n",
    "\n",
    "\n",
    "# Detectron2 Model Size\n",
    "detectron2_path = \"C:\\\\Users\\\\lewis/.torch/iopath_cache\\\\s/d9fc9tahfzyl6df\\\\model_final.pth\"\n",
    "weights = torch.load(detectron2_path, map_location=torch.device(\"cpu\"))\n",
    "# If the file contains a Detectron2 model checkpoint, extract the state_dict\n",
    "if \"model\" in weights:\n",
    "    weights = weights[\"model\"]\n",
    "# Count total parameters\n",
    "total_params = sum(p.numel() for p in weights.values())\n",
    "print(f\"Total number of parameters (Detectron2): {total_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
