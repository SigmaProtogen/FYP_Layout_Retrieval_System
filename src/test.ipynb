{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layoutparser as lp\n",
    "import pymupdf\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lp.Detectron2LayoutModel('lp://PubLayNet/mask_rcnn_R_50_FPN_3x/config', \n",
    "                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n",
    "                                 label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3:\"Table\", 4:\"Figure\"})\n",
    "doc = pymupdf.open(\"../data/1706.03762.pdf\")\n",
    "page = doc[2].get_pixmap(dpi=300)\n",
    "\n",
    "# Convert to cv2 format\n",
    "bytes = np.frombuffer(page.samples, dtype=np.uint8)\n",
    "image = bytes.reshape(page.height, page.width, page.n)\n",
    "image = image[..., ::-1] \n",
    "\n",
    "layout = model.detect(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate boxes by category\n",
    "text_blocks = lp.Layout([b for b in layout if b.type=='Text'])\n",
    "figure_blocks = lp.Layout([b for b in layout if b.type=='Figure'])\n",
    "text_blocks = lp.Layout([b for b in text_blocks \\\n",
    "                   if not any(b.is_in(b_fig) for b_fig in figure_blocks)])\n",
    "\n",
    "# Sort boxes\n",
    "h, w = image.shape[:2]\n",
    "\n",
    "left_interval = lp.Interval(0, w/2*1.05, axis='x').put_on_canvas(image)\n",
    "\n",
    "left_blocks = text_blocks.filter_by(left_interval, center=True)\n",
    "left_blocks.sort(key = lambda b:b.coordinates[1], inplace=True)\n",
    "# The b.coordinates[1] corresponds to the y coordinate of the region\n",
    "# sort based on that can simulate the top-to-bottom reading order \n",
    "right_blocks = lp.Layout([b for b in text_blocks if b not in left_blocks])\n",
    "right_blocks.sort(key = lambda b:b.coordinates[1], inplace=True)\n",
    "\n",
    "# And finally combine the two lists and add the index\n",
    "text_blocks = lp.Layout([b.set(id = idx) for idx, b in enumerate(left_blocks + right_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR on regions of interest\n",
    "ocr_agent = lp.TesseractAgent(languages='eng') \n",
    "\n",
    "for block in text_blocks:\n",
    "    segment_image = (block.pad(left=5, right=5, top=5, bottom=5).crop_image(image))\n",
    "        # add padding in each image segment can help\n",
    "        # improve robustness \n",
    "    text = ocr_agent.detect(segment_image)\n",
    "    block.set(text=text, inplace=True) # Assign parsed text to block element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\n",
      "connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\n",
      "respectively.\n",
      "\n",
      "---\n",
      "Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\n",
      "sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\n",
      "wise fully connected feed-forward network. We employ a residual connection [11] around each of\n",
      "the two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\n",
      "LayerNorm(x + Sublayer(Â«)), where Sublayer() is the function implemented by the sub-layer\n",
      "itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\n",
      "layers, produce outputs of dimension diode} = 512.\n",
      "\n",
      "---\n",
      "Decoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two\n",
      "sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\n",
      "attention over the output of the encoder stack. Similar to the encoder, we employ residual connections\n",
      "around each of the sub-layers, followed by layer normalization. We also modify the self-attention\n",
      "sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\n",
      "masking, combined with fact that the output embeddings are offset by one position, ensures that the\n",
      "predictions for position 2 can depend only on the known outputs at positions less than 7.\n",
      "\n",
      "---\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for txt in text_blocks.get_texts():\n",
    "    print(txt, end='\\n---\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
